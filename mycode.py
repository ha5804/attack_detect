import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

class Data:
    def __init__(self):
        self.test = ("./data/kdd99_test.csv")
        self.train = ("./data/kdd99_train.csv")
        
    def read_data(self, dir):
        data = pd.read_csv(dir)
        return data
    
    def make_feature(self, df):
        x = df.drop(columns = ["Attack Type"])
        return x
    
    def make_label(self, df):
        y = df["Attac Type"]
        return y
    
    def remove_duplicated(self, df):
        df = df.drop_duplicats()
        return df
    
    def remove_nan(self, df):
        df = df.dropna()
        return df
    
    def pca(self, df, k = 1):
        x = df - df.mean(axis = 0)
        cov_matrix = np.cov(x)
        eigen_val, eigen_vec = np.linalg.eig(cov_matrix)
        idx = np.argsort(eigen_val)[::-1]
        eigen_vec = eigen_vec[:, idx]
        p_c = eigen_vec[: , :k]
        x_pca = np.dot(x, p_c)
        return x_pca

    def pearson(self, x):
        drop_set = set() #ë‚˜ì¤‘ì— ì œê±°í•´ì•¼í•  feature ì´ë¦„ì €ì¥í•˜ëŠ” ë¹ˆ ì§‘í•©
        corr_matrix = x.corr().abs() #xì˜ ëª¨ë“  featureê°„ì˜ í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ ê³„ì‚°í›„ ì ˆëŒ€ê°’
        for i, col in enumerate(corr_matrix.columns): #indexë²ˆí˜¸ iì™€ ì—´ì´ë¦„ ìˆœì„œëŒ€ë¡œ ì¶”ì¶œ
            if col not in drop_set:
                for j, col2 in enumerate(corr_matrix.columns):
                    if i < j: #mask, ëŒ€ì¹­í–‰ë ¬ì´ë¯€ë¡œ ìƒì‚¼ê°í–‰ë ¬ë§Œ ê³„ì‚°
                        corr_value = corr_matrix.iloc[i, j]
                        if corr_value >= 0.9:
                            #ilocìœ¼ë¡œ indexë²ˆí˜¸ë¡œ ì ‘ê·¼, locì€ í–‰ ì—´ ì´ë¦„ìœ¼ë¡œ ì ‘ê·¼
                            if x[col].var() >= x[col2].var():
                                
                                drop_set.add(col2)
                            else:
                                drop_set.add(col)
        
        print("remove feature: ", drop_set)
        print(len(drop_set))
        x = x.drop(columns= list(drop_set)) #setìœ¼ë¡œ ì €ì¥í•œ ê²°ê³¼ë¥¼ listë°˜í™˜í›„ col ì´ë¦„ìœ¼ë¡œ ì œê³µ
        return x
                        

class baysian:
    def __init__(self):
        pass
    
    #ê° í´ë˜ìŠ¤ì˜ í™•ë¥ 
    def probability(self, y):
        count = 0
        for i in y:
            if i == 1:
                count += 1
        p_y_1 = count / len(y)
        p_y_0 = 1 - (count / len(y))
        return p_y_1 , p_y_0
    
    #ì—°ì†í˜• ë² ì´ì§€ì•ˆì€ ê°€ìš°ì‹œì•ˆ ë¶„í¬ë¡œ ì˜ˆì¸¡
    #ì •ë‹µì´ 1ê³¼ 0 ì¸ x ë¶„í¬ì˜ í‰ê·  í‘œì¤€í¸ì°¨ë¥¼ ê°ê° êµ¬í•¨
    def condition_p(self, x, y):
        x = np.array(x, dtype=float)
        y = np.array(y, dtype=int)
        x_y1 = x[y == 1]
        x_y0 = x[y == 0]

        mean_y1 = np.mean(x_y1, axis=0)
        std_y1  = np.std(x_y1, axis=0)
        mean_y0 = np.mean(x_y0, axis=0)
        std_y0  = np.std(x_y0, axis=0)

        # ğŸ”¹ í‘œì¤€í¸ì°¨ 0 ë³´ì •
        std_y1 = np.where(std_y1 == 0, 1e-6, std_y1)
        std_y0 = np.where(std_y0 == 0, 1e-6, std_y0)

        return mean_y1, std_y1, mean_y0, std_y0
    
    def gaussian_prob(self, x, mean, std):
        x = np.array(x, dtype=float) #xë¥¼ numpyë¡œ ë³€í™˜í›„ floatìœ¼ë¡œ ì„¤ì •.
        exponent = np.exp(-((x - mean) ** 2) / (2 * std ** 2))
        prob = (1 / (np.sqrt(2 * np.pi) * std)) * exponent
        return np.where(np.isnan(prob), 1e-12, prob)  # ğŸ”¹ NaN ë°©ì§€
    #np.where(condition, A, B) ì¡°ê±´ ë”°ë¼ ê°’ ì„ íƒí›„ ë°°ì—´ ë°˜í™˜ trueë©´ 1e-12, ì•„ë‹ˆë©´ prob
    

    def predict(self, x_train, y_train, new_x):
        p_y1, p_y0 = self.probability(y_train)

        mean_y1, std_y1, mean_y0, std_y0 = self.condition_p(x_train, y_train)

        p_x_y1 = self.gaussian_prob(new_x, mean_y1, std_y1)
        p_x_y0 = self.gaussian_prob(new_x, mean_y0, std_y0)

        log_post_y1 = np.sum(np.log(p_x_y1 + 1e-12), axis=1) + np.log(p_y1)
        log_post_y0 = np.sum(np.log(p_x_y0 + 1e-12), axis=1) + np.log(p_y0)

        y_hat = (log_post_y1 > log_post_y0).astype(int)
        return y_hat

class eval:
    def __init__(self):
        pass

    def metrics_np(self, y_true, y_pred):
        y_true = np.array(y_true)
        y_pred = np.array(y_pred)

        TP = np.sum((y_true == 1) & (y_pred == 1))
        TN = np.sum((y_true == 0) & (y_pred == 0))
        FP = np.sum((y_true == 0) & (y_pred == 1))
        FN = np.sum((y_true == 1) & (y_pred == 0))

        eps = 1e-10

        accuracy = (TP + TN) / (TP + TN + FP + FN + eps)
        accuracy  = (TP + TN) / (TP + TN + FP + FN + eps)
        precision = TP / (TP + FP + eps)
        recall    = TP / (TP + FN + eps)
        f1_score  = 2 * precision * recall / (precision + recall + eps)

        return accuracy, precision, recall, f1_score

    
        
#ì´ì‚°í˜• ë¶„í¬ëŠ” ì„¸ì„œ ê³„ì‚°í•˜ì§€ë§Œ ì—°ì†í˜• ë¶„í¬ì˜ê²½ìš°ì—ëŠ” ì •ê·œë¶„í¬ë¡œ ë³€í™˜í›„ ì¡°ê±´ë¶€í™•ë¥  ê³„ì‚°í•´ì•¼í•¨.

    
    
        